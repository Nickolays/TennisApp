# Training Configuration for Court Detection Model

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
model:
  out_channels: 14              # 14 court keypoints
  pretrained: false

# ============================================================================
# DATASET CONFIGURATION
# ============================================================================
data:
  # Court dataset
  ann_file: "data/tennis_court_dataset/train/_annotations.coco.json"
  img_dir: "data/tennis_court_dataset/train"
  target_size: [512, 512]       # Same as notebook (working configuration)
  train_split: 0.85             # 85% train, 15% validation

# ============================================================================
# TRAINING CONFIGURATION
# ============================================================================
training:
  batch_size: 2                 # Same as notebook (limited by GPU memory)
  accumulation_steps: 8         # Effective batch size = 2 * 8 = 16
  num_epochs: 10                # Reduced for testing stability
  initial_lr: 0.0002            # Reduced from 0.0005 but not too low
  min_lr: 0.00001               # Minimum LR
  weight_decay: 0.0001          # Same as notebook (0.0001)
  grad_clip: 2.0                # Moderate clipping (not too aggressive)
  mixed_precision: false        # Disable for stability (notebook doesn't use it)
  warmup_epochs: 0              # No warmup - keep it simple

# ============================================================================
# OPTIMIZER & SCHEDULER CONFIGURATION
# ============================================================================
optimizer:
  type: "adamw"                 # AdamW optimizer
  betas: [0.9, 0.999]
  eps: 0.00000001

scheduler:
  type: "linear"                # LinearLR - same as notebook
  start_factor: 1.0             # Start at 100% of initial LR
  end_factor: 0.1               # End at 10% of initial LR (0.00005)
  # Linear decay from 0.0005 to 0.00005 over all epochs

# ============================================================================
# LOSS FUNCTION CONFIGURATION
# ============================================================================
loss:
  type: "mse"                   # MSE on heatmaps - back to working config
  # MSE worked well for epochs 1-6, we just need to prevent collapse

# ============================================================================
# VALIDATION & CHECKPOINTING
# ============================================================================
validation:
  val_interval: 1               # Validate every epoch
  save_best: true               # Save best model
  early_stopping_patience: 25   # Stop if no improvement for 25 epochs (was 15)

checkpoint:
  checkpoint_dir: "checkpoints/court_detection"
  save_interval: 10             # Save checkpoint every 10 epochs (not every 5)
  save_final: true              # Save final model
  save_best_only: false         # Also save periodic checkpoints

# ============================================================================
# OUTPUT CONFIGURATION
# ============================================================================
output:
  log_dir: "logs"
  log_file: "logs/court_training.json"
  tensorboard: false            # Disable for now (saves disk space)

# ============================================================================
# SYSTEM CONFIGURATION
# ============================================================================
system:
  device: "cuda"                # cuda or cpu
  num_workers: 4                # DataLoader workers
  pin_memory: true              # Pin memory for faster GPU transfer
  deterministic: false          # Set to true for reproducible results (slower)
  seed: 42                      # Random seed

# ============================================================================
# NOTES
# ============================================================================
# GPU Memory Usage (RTX 3070 8GB):
#   - batch_size=4, target_size=640: ~6GB (safe)
#   - batch_size=8, target_size=640: ~10GB (out of memory)
#   - batch_size=4, target_size=512: ~4GB (underutilized)
#
# Training Time:
#   - ~3-4 hours on RTX 3070 with these settings
#   - ~50 epochs, 918 images, batch_size=4
#
# Expected Results:
#   - Mean error: ~2 pixels
#   - PCK@10px: >99%
#   - Val loss: ~5
